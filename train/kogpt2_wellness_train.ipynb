{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SD_GVjsI5eHq","executionInfo":{"status":"ok","timestamp":1706141854186,"user_tz":-540,"elapsed":10,"user":{"displayName":"Seulbi Ryu","userId":"10359868065208831031"}},"outputId":"888f3da5-3f24-47ad-f53b-fe0c75b7003d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jan 25 00:17:33 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              26W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ROT9bIG3DWU","executionInfo":{"status":"ok","timestamp":1706141875326,"user_tz":-540,"elapsed":21147,"user":{"displayName":"Seulbi Ryu","userId":"10359868065208831031"}},"outputId":"653269cb-b952-4225-f2a1-60a1bea1cf81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torch\n","!pip install kogpt2_transformers\n","!pip install transformers\n","!pip install tokenizers"],"metadata":{"id":"sLUGoK1l3HXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# module, library import\n","\n","# dataloader\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from kogpt2_transformers import get_kogpt2_tokenizer\n","\n","# model configuration\n","import logging\n","from transformers.configuration_utils import PretrainedConfig\n","from transformers import GPT2Config\n","# model\n","# import torch.nn as nn\n","from kogpt2_transformers import get_kogpt2_model\n","\n","# train\n","import sys\n","sys.path.append('/content/drive/MyDrive/my_ws/project/aischool-final/dialogLM')\n","\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","# import torch\n","from torch.utils.data import dataloader\n","# from dialogLM.dataloader.wellness import WellnessAutoRegressiveDataset\n","# from dialogLM.model.kogpt2 import DialogKoGPT2\n","\n","import csv"],"metadata":{"id":"SgkftvBo3Hcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataloader\n","class WellnessAutoRegressiveDataset(Dataset):\n","  \"\"\"Wellness Auto Regressive Dataset\"\"\"\n","  def __init__(self,\n","               file_path,\n","               n_ctx = 1024\n","               ):\n","    self.file_path = file_path\n","    self.data =[]\n","    self.tokenizer = get_kogpt2_tokenizer()\n","\n","    bos_token_id = [self.tokenizer.bos_token_id]\n","    eos_token_id = [self.tokenizer.eos_token_id]\n","    pad_token_id = [self.tokenizer.pad_token_id]\n","\n","    file = open(self.file_path, 'r', encoding='utf-8')\n","\n","    while True:\n","      line = file.readline()\n","      if not line:\n","        break\n","      datas = line.split(\"    \")\n","      index_of_words = bos_token_id +self.tokenizer.encode(datas[0]) + eos_token_id + bos_token_id + self.tokenizer.encode(datas[1][:-1])+ eos_token_id\n","      pad_token_len = n_ctx - len(index_of_words)\n","\n","      index_of_words += pad_token_id * pad_token_len\n","\n","      self.data.append(index_of_words)\n","\n","    file.close()\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self,index):\n","    item = self.data[index]\n","    return item\n","\n","# model configuration\n","logger = logging.getLogger(__name__)\n","\n","#KoGPT2 configuration\n","kogpt2_config = {\n","    \"initializer_range\": 0.02,\n","    \"layer_norm_epsilon\": 1e-05,\n","    \"n_ctx\": 1024,\n","    \"n_embd\": 768,\n","    \"n_head\": 12,\n","    \"n_layer\": 12,\n","    \"n_positions\": 1024,\n","    \"vocab_size\": 50000,\n","    \"activation_function\": \"gelu\"\n","}\n","\n","def get_kogpt2_config():\n","    return GPT2Config.from_dict(kogpt2_config)\n","\n","# model\n","class DialogKoGPT2(nn.Module):\n","  def __init__(self):\n","    super(DialogKoGPT2, self).__init__()\n","    self.kogpt2 = get_kogpt2_model()\n","\n","  def generate(self,\n","               input_ids,\n","               do_sample=True,\n","               max_length= 60,\n","               top_p=0.92,\n","               top_k=50,\n","               temperature= 0.6,\n","               no_repeat_ngram_size=None,\n","               num_return_sequences=1,\n","               early_stopping=False,\n","               ):\n","    return self.kogpt2.generate(input_ids,\n","               do_sample=do_sample,\n","               max_length=max_length,\n","               top_p=top_p,\n","               top_k=top_k,\n","               temperature=temperature,\n","               no_repeat_ngram_size=no_repeat_ngram_size,\n","               num_return_sequences=num_return_sequences,\n","               early_stopping = early_stopping,\n","              )\n","\n","  def forward(self, input, labels = None):\n","    if labels is not None:\n","      outputs = self.kogpt2(input, labels=labels)\n","    else:\n","      outputs = self.kogpt2(input)\n","    return outputs"],"metadata":{"id":"CJxFfNB83HgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpisrq455LJu","executionInfo":{"status":"ok","timestamp":1706143862858,"user_tz":-540,"elapsed":697,"user":{"displayName":"Seulbi Ryu","userId":"10359868065208831031"}},"outputId":"8d9475a5-fe16-4d06-c2ed-f4687ca1a0ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 학습\n","root_path = '/content/drive/MyDrive/my_ws/project/aischool-final/dialogLM'\n","train_data_path = f\"{root_path}/data/wellness_dialog_for_autoregressive_train.txt\"\n","val_data_path = f\"{root_path}/data/wellness_dialog_for_autoregressive_validation.txt\"\n","save_ckpt_path = f\"{root_path}/checkpoint/kogpt2-wellnesee-auto-regressive_hi.pth\"\n","\n","batch_size = 2\n","ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(ctx)\n","\n","n_epoch = 10\n","save_step = 100\n","learning_rate = 5e-5\n","\n","\n","# Training data loader\n","train_dataset = WellnessAutoRegressiveDataset(train_data_path)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Validation data loader\n","val_dataset = WellnessAutoRegressiveDataset(val_data_path)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Model initialization\n","model = DialogKoGPT2()\n","model.to(device)\n","\n","# Loss function and optimizer\n","loss_fct = torch.nn.CrossEntropyLoss(ignore_index=3)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","losses = []\n","val_losses = []\n","\n","# 최소 손실값 초기화\n","min_val_loss = 999\n","\n","with open(f'{root_path}/training_log.csv', 'a', newline='') as train_file:\n","  train_writer = csv.writer(train_file)\n","  with open(f'{root_path}/valid_log.csv', 'a', newline='') as valid_file:\n","    valid_writer = csv.writer(valid_file)\n","    for epoch in range(n_epoch):\n","      count = 0\n","      with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n","        for i, data in enumerate(train_loader):\n","          optimizer.zero_grad()\n","          data = torch.stack(data)\n","          data = data.transpose(1, 0)\n","          data = data.to(ctx)\n","\n","          outputs = model(data, labels=data)\n","          _, logits = outputs[:2]\n","\n","          shift_logits = logits[..., :-1, :].contiguous()\n","          shift_labels = data[..., 1:].contiguous()\n","\n","          loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","          loss.backward()\n","          optimizer.step()\n","\n","          losses.append(loss.item())\n","\n","          # 체크포인트 저장\n","          if (count > 0 and count % save_step == 0) or (len(data) < batch_size):\n","            torch.save({\n","              'epoch': epoch,\n","              'train_no': count,\n","              'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'loss': loss\n","            }, f'/content/drive/MyDrive/my_ws/project/aischool-final/dialogLM/checkpoint/kogpt2-wellnesee-auto-regressive_hi_{epoch}.pth')\n","\n","            # CSV 파일에 내용 추가\n","            train_writer.writerow([epoch,i,loss.item(),np.mean(losses)])\n","\n","          # 최소 손실값 업데이트 및 체크포인트 저장\n","          if loss < min_val_loss:\n","              min_val_loss = loss\n","              torch.save({\n","                  'epoch': epoch,\n","                  'train_no': count,\n","                  'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'loss': loss\n","              }, f\"{root_path}/checkpoint/kogpt2-wellnesee-auto-regressive_best.pth\")\n","          count += 1\n","          pbar.update(1)\n","          pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")\n","\n","      # Validation loop\n","      with torch.no_grad():\n","        model.eval()\n","        with tqdm(total=len(val_loader), desc=f\"Validation\") as val_pbar:\n","          for j, val_data in enumerate(val_loader):\n","            val_data = torch.stack(val_data)\n","            val_data = val_data.transpose(1, 0)\n","            val_data = val_data.to(ctx)\n","\n","            val_outputs = model(val_data, labels=val_data)\n","            _, val_logits = val_outputs[:2]\n","\n","            val_shift_logits = val_logits[..., :-1, :].contiguous()\n","            val_shift_labels = val_data[..., 1:].contiguous()\n","\n","            val_loss = loss_fct(val_shift_logits.view(-1, val_shift_logits.size(-1)), val_shift_labels.view(-1))\n","            val_losses.append(val_loss.item())\n","\n","            valid_writer.writerow([epoch,j,val_loss.item(),np.mean(val_losses)])\n","\n","            val_pbar.update(1)\n","            val_pbar.set_postfix_str(f\"Validation Loss: {val_loss.item():.3f} ({np.mean(val_losses):.3f})\")\n","      model.train()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00S6LgB33Hjk","executionInfo":{"status":"ok","timestamp":1706163123940,"user_tz":-540,"elapsed":18420762,"user":{"displayName":"Seulbi Ryu","userId":"10359868065208831031"}},"outputId":"969702a0-2be6-4b51-fde3-d2d2511ddc8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","Train(0): 100%|██████████| 6343/6343 [30:43<00:00,  3.44it/s, Loss: 1.053 (1.963)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.39it/s, Validation Loss: 2.231 (1.467)]\n","Train(1): 100%|██████████| 6343/6343 [29:11<00:00,  3.62it/s, Loss: 1.027 (1.680)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.27it/s, Validation Loss: 2.236 (1.345)]\n","Train(2): 100%|██████████| 6343/6343 [29:12<00:00,  3.62it/s, Loss: 0.900 (1.470)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.37it/s, Validation Loss: 2.005 (1.233)]\n","Train(3): 100%|██████████| 6343/6343 [29:37<00:00,  3.57it/s, Loss: 0.731 (1.309)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.22it/s, Validation Loss: 1.747 (1.136)]\n","Train(4): 100%|██████████| 6343/6343 [29:36<00:00,  3.57it/s, Loss: 0.690 (1.185)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.29it/s, Validation Loss: 1.835 (1.058)]\n","Train(5): 100%|██████████| 6343/6343 [29:23<00:00,  3.60it/s, Loss: 0.697 (1.088)]\n","Validation: 100%|██████████| 793/793 [01:03<00:00, 12.44it/s, Validation Loss: 1.790 (0.996)]\n","Train(6): 100%|██████████| 6343/6343 [29:23<00:00,  3.60it/s, Loss: 0.411 (1.011)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.25it/s, Validation Loss: 1.906 (0.947)]\n","Train(7): 100%|██████████| 6343/6343 [29:50<00:00,  3.54it/s, Loss: 0.437 (0.949)]\n","Validation: 100%|██████████| 793/793 [01:05<00:00, 12.12it/s, Validation Loss: 2.080 (0.909)]\n","Train(8): 100%|██████████| 6343/6343 [29:28<00:00,  3.59it/s, Loss: 0.369 (0.897)]\n","Validation: 100%|██████████| 793/793 [01:04<00:00, 12.25it/s, Validation Loss: 1.814 (0.878)]\n","Train(9): 100%|██████████| 6343/6343 [29:41<00:00,  3.56it/s, Loss: 0.438 (0.854)]\n","Validation: 100%|██████████| 793/793 [01:05<00:00, 12.17it/s, Validation Loss: 2.096 (0.853)]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","pd.DataFrame(losses).to_csv(f'{root_path}/hi_losses.csv',index=False)\n","pd.DataFrame(val_losses).to_csv(f'{root_path}/hi_val_losses.csv',index=False)"],"metadata":{"id":"syfE7-Jl3Hm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KsGmpZQ83Hrj"},"execution_count":null,"outputs":[]}]}