{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18054,
     "status": "ok",
     "timestamp": 1706267288891,
     "user": {
      "displayName": "Seul bi Ryu",
      "userId": "15935787459018359561"
     },
     "user_tz": -540
    },
    "id": "TrL36Qr7bOC3",
    "outputId": "5a1d0e40-9844-4282-8622-71bd02c9333a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43771,
     "status": "ok",
     "timestamp": 1706267731510,
     "user": {
      "displayName": "Seul bi Ryu",
      "userId": "15935787459018359561"
     },
     "user_tz": -540
    },
    "id": "7gjx4iccDl_K",
    "outputId": "4facef64-6712-4c24-af8e-f2456f36a1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/my_ws/project/aischool-final/dialogLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of koElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrain from: /content/drive/MyDrive/AISCHOOL9기-FINAL/koelectra/koelectra-wellness-text-classification-25-train.pth, epoch=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:33<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.2260(valid)\t|\tAcc: 32.0%(valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "  AdamW,\n",
    "  ElectraConfig,\n",
    "  ElectraTokenizer\n",
    ")\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "# Change working directory\n",
    "%cd /content/drive/MyDrive/my_ws/project/aischool-final/dialogLM\n",
    "\n",
    "from dataloader.wellness import WellnessTextClassificationDataset\n",
    "from model.koelectra import koElectraForSequenceClassification\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Model class mapping\n",
    "MODEL_CLASSES ={\n",
    "  \"koelectra\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer)\n",
    "}\n",
    "\n",
    "# Path to trained model checkpoint\n",
    "CHECK_POINT ={\n",
    "  \"koelectra\": \"/content/drive/MyDrive/AISCHOOL9기-FINAL/koelectra/koelectra-wellness-text-classification-25-train.pth\"\n",
    "}\n",
    "\n",
    "# Load model and tokenizer\n",
    "def get_model_and_tokenizer(model_name, device):\n",
    "  save_ckpt_path = CHECK_POINT[model_name]\n",
    "\n",
    "  if model_name== \"koelectra\":\n",
    "    model_name_or_path = \"monologg/koelectra-base-discriminator\"\n",
    "\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(model_name_or_path)\n",
    "    electra_config = ElectraConfig.from_pretrained(model_name_or_path)\n",
    "    model = koElectraForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path,\n",
    "                                                               config=electra_config,\n",
    "                                                               num_labels=359)\n",
    "  # Load checkpoint\n",
    "  if os.path.isfile(save_ckpt_path):\n",
    "      checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
    "      pre_epoch = checkpoint['epoch']\n",
    "      # pre_loss = checkpoint['loss']\n",
    "      model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "\n",
    "      print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")\n",
    "\n",
    "  return model, tokenizer\n",
    "\n",
    "# Format model input\n",
    "def get_model_input(data):\n",
    "  if model_name== \"koelectra\":\n",
    "    return {'input_ids': data['input_ids'],\n",
    "              'attention_mask': data['attention_mask'],\n",
    "              'labels': data['labels']\n",
    "              }\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model_name, device, batch_size, data_path):\n",
    "\n",
    "  model, tokenizer = get_model_and_tokenizer(model_name, device)\n",
    "  model.to(device)\n",
    "\n",
    "  # Load evaluation dataset\n",
    "  eval_dataset = WellnessTextClassificationDataset(file_path=data_path,device=device, tokenizer=tokenizer)\n",
    "\n",
    "  # ❗ shuffle=True is not typical for evaluation but does not affect overall metrics like accuracy\n",
    "  eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  logger.info(\"***** Running evaluation on %s dataset *****\")\n",
    "  logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "  logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "  loss = 0\n",
    "  acc = 0\n",
    "\n",
    "  model.eval()\n",
    "  for data in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    with torch.no_grad():\n",
    "      inputs = get_model_input(data)\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "      # ❗ Loss is accumulated without normalization per sample count.\n",
    "      # This is not the exact average loss.\n",
    "      loss += outputs[0]\n",
    "      logit = outputs[1]\n",
    "      # Count correct predictions and convert tensor to Python number\n",
    "      acc += (logit.argmax(1)==inputs['labels']).sum().item()\n",
    "\n",
    "  # Normalize loss and accuracy by total number of samples\n",
    "  return loss / len(eval_dataset), acc / len(eval_dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # Path to evaluation data\n",
    "  data_path = f\"/content/drive/MyDrive/my_ws/project/aischool-final/dialogLM/data/wellness_data_for_text_classification_test.txt\"\n",
    "  # Checkpoint path\n",
    "  save_ckpt_path = f\"/content/drive/MyDrive/AISCHOOL9기-FINAL/koelectra/koelectra-wellness-text-classification-25-train.pth\"\n",
    "\n",
    "  model_name_or_path = \"monologg/koelectra-base-discriminator\"\n",
    "\n",
    "  batch_size = 16   # Batch size for evaluation\n",
    "\n",
    "  ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  device = torch.device(ctx)\n",
    "\n",
    "  model_names=[\"koelectra\"]\n",
    "  for model_name in model_names:\n",
    "    eval_loss, eval_acc = evaluate(model_name, device, batch_size, data_path)\n",
    "    print(f'\\tLoss: {eval_loss:.4f}(valid)\\t|\\tAcc: {eval_acc * 100:.1f}%(valid)')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
